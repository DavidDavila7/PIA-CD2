{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex4PKxctbwTt"
   },
   "source": [
    "Implementacion recuperada de:\n",
    "\n",
    "https://github.com/shivamduseja/Deep-Summarization/blob/master/LSTM_with_attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xza3ADYQaRFQ",
    "outputId": "bcc51c4a-3c5d-418f-c5bc-49a1bd0f348d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePLgQmUMSuB3",
    "outputId": "ac9d599c-8745-429b-ea9b-5e54427df718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H-4Ht48akoOg"
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "#dbfile = '/content/drive/MyDrive/NoticiasReforma2009.db'\n",
    "dbfile='D:/Computo Estadistico/PIA-CD2/NoticiasReforma2009.db' #david pc\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import sqlalchemy \n",
    "\n",
    "try:\n",
    "    con = sqlite3.connect(dbfile)    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i6DiECQSr9V",
    "outputId": "65cb370f-8581-4e62-cfef-edd16f720b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Name : [('Reforma2009',), ('Noticias2009',)]\n"
     ]
    }
   ],
   "source": [
    "#Now in order to read in pandas dataframe we need to know table name\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(f\"Table Name : {cursor.fetchall()}\")\n",
    "\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM Noticias2009', con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "oKL-Lsk-yaxk",
    "outputId": "0ebf6060-edbe-45fc-9b60-112462df4286"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>titulo</th>\n",
       "      <th>links</th>\n",
       "      <th>seccion</th>\n",
       "      <th>medio</th>\n",
       "      <th>autor</th>\n",
       "      <th>resumen</th>\n",
       "      <th>articulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-Ene-2009</td>\n",
       "      <td>Fallan Zunes de Microsoft</td>\n",
       "      <td>https://busquedas.gruporeforma.com/reforma/Doc...</td>\n",
       "      <td>Gadgets</td>\n",
       "      <td>Reforma</td>\n",
       "      <td>AP</td>\n",
       "      <td>Los reproductores de música Zune dejan de func...</td>\n",
       "      <td>\\n                        Fallan reproductores...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-Ene-2009</td>\n",
       "      <td>SAN CADILLA</td>\n",
       "      <td>https://busquedas.gruporeforma.com/reforma/Doc...</td>\n",
       "      <td>editoriales</td>\n",
       "      <td>Reforma</td>\n",
       "      <td></td>\n",
       "      <td>Se pasan de trabajadores\\n \\nMientras hoy uste...</td>\n",
       "      <td>\\n                        SAN CADILLASe pasan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-Ene-2009</td>\n",
       "      <td>ALEPH CERO / Materia vs. antimateria</td>\n",
       "      <td>https://busquedas.gruporeforma.com/reforma/Doc...</td>\n",
       "      <td>editoriales</td>\n",
       "      <td>Reforma</td>\n",
       "      <td>Shahen Hacyan</td>\n",
       "      <td>En el Principio eran la luz, la materia y la a...</td>\n",
       "      <td>\\n                        ALEPH CERO / Materia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-Ene-2009</td>\n",
       "      <td>GACETA DEL ÁNGEL / Yo soy macho donde qu</td>\n",
       "      <td>https://busquedas.gruporeforma.com/reforma/Doc...</td>\n",
       "      <td>editoriales</td>\n",
       "      <td>Reforma</td>\n",
       "      <td>Germán Dehesa</td>\n",
       "      <td>ANTECEDENTES: el día de ayer, mientras confecc...</td>\n",
       "      <td>\\n                        GACETA DEL ÁNGEL / Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-Ene-2009</td>\n",
       "      <td>CIRCUITO INTERIOR</td>\n",
       "      <td>https://busquedas.gruporeforma.com/reforma/Doc...</td>\n",
       "      <td>editoriales</td>\n",
       "      <td>Reforma</td>\n",
       "      <td></td>\n",
       "      <td>Unos tristes, otros contentos\\n \\n \\nLOS QUE a...</td>\n",
       "      <td>\\n                        CIRCUITO INTERIORUno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fecha                                    titulo  \\\n",
       "0  01-Ene-2009                 Fallan Zunes de Microsoft   \n",
       "1  01-Ene-2009                               SAN CADILLA   \n",
       "2  01-Ene-2009      ALEPH CERO / Materia vs. antimateria   \n",
       "3  01-Ene-2009  GACETA DEL ÁNGEL / Yo soy macho donde qu   \n",
       "4  01-Ene-2009                         CIRCUITO INTERIOR   \n",
       "\n",
       "                                               links      seccion    medio  \\\n",
       "0  https://busquedas.gruporeforma.com/reforma/Doc...      Gadgets  Reforma   \n",
       "1  https://busquedas.gruporeforma.com/reforma/Doc...  editoriales  Reforma   \n",
       "2  https://busquedas.gruporeforma.com/reforma/Doc...  editoriales  Reforma   \n",
       "3  https://busquedas.gruporeforma.com/reforma/Doc...  editoriales  Reforma   \n",
       "4  https://busquedas.gruporeforma.com/reforma/Doc...  editoriales  Reforma   \n",
       "\n",
       "           autor                                            resumen  \\\n",
       "0             AP  Los reproductores de música Zune dejan de func...   \n",
       "1                 Se pasan de trabajadores\\n \\nMientras hoy uste...   \n",
       "2  Shahen Hacyan  En el Principio eran la luz, la materia y la a...   \n",
       "3  Germán Dehesa  ANTECEDENTES: el día de ayer, mientras confecc...   \n",
       "4                 Unos tristes, otros contentos\\n \\n \\nLOS QUE a...   \n",
       "\n",
       "                                            articulo  \n",
       "0  \\n                        Fallan reproductores...  \n",
       "1  \\n                        SAN CADILLASe pasan ...  \n",
       "2  \\n                        ALEPH CERO / Materia...  \n",
       "3  \\n                        GACETA DEL ÁNGEL / Y...  \n",
       "4  \\n                        CIRCUITO INTERIORUno...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-9t3j9flEPG",
    "outputId": "303a178f-66c0-453f-de58-f5586ee97a57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\david\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-vf5_Yn_rZ_"
   },
   "source": [
    "Preprocesamos las noticias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-eMMVjyrkvgk"
   },
   "outputs": [],
   "source": [
    "stopSpanish=set(stopwords.words('spanish'))\n",
    "noticias=[]\n",
    "for i in range (61035):\n",
    "  text_tokens = word_tokenize(df['articulo'][i])\n",
    "  tokens_without_sw = [word for word in text_tokens if not word in stopSpanish]\n",
    "  tokens_without_sw = [word.lower() for word in tokens_without_sw if word.isalpha()]\n",
    "  noticias.append(' '.join(tokens_without_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCdy-EVr_17W"
   },
   "source": [
    "Preprocesamos los resumenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rddBUYPvyMPs"
   },
   "outputs": [],
   "source": [
    "stopSpanish=set(stopwords.words('spanish'))\n",
    "resumen=[]\n",
    "for i in range (len(df['resumen'])):\n",
    "  text_tokens = word_tokenize(df['resumen'][i])\n",
    "  tokens_without_sw = [word for word in text_tokens if not word in stopSpanish]\n",
    "  tokens_without_sw = [word.lower() for word in tokens_without_sw if word.isalpha()]\n",
    "  resumen.append(' '.join(tokens_without_sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lj-_iT9PplHe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61035"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noticias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bTQ838XeB4LK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fallan reproductores zune microsoft en año nuevo usuarios popular reproductor música zune microsoft pudieron escuchar reproductores zune microsoft respuesta gigante software populares ipod empresa apple dejaron funcionar inesperadamente noche ayer mostraban usuarios mensaje error llevó referencias colapso zunes el problema surgió gente intentó hacer funcionar usuarios buscaron foros ayuda microsoft zune inundaron portal mil empresa sede redmond washington informó problema afectó sólo modelos gigabytes zune provocado problema reloj esperaba problema resuelva tan pronto relojes pasen fecha enero aunque usuarios deberán adoptar varias medidas aparatos funcionen normalmente dejar baterías acaben completo aparatos reinicien falla tantos reproductores mismo tiempo trajo comparaciones problema programación año generó temores crisis generalizada computadoras mundo máquinas avanzaban nuevo reproductores zune populares comparación ipods controla aproximadamente tres cuartas partes mercado reproductores música los zune menos ciento mercado acuerdo estadísticas npd embargo usuarios sido leales marca nuevos modelos zune recibido críticas favorables'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noticias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1qBtIn-DyyRs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'los reproductores música zune dejan funcionar noche año nuevo mientras microsoft afirma normalizará enero'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "86NghnNUlxFU"
   },
   "outputs": [],
   "source": [
    "data={'Noticia': noticias, 'Resumen Original': df['resumen'][:], 'Resumen Procesado': resumen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eINz8dnbmVNi",
    "outputId": "13426ada-2030-4066-9605-acda1f6a1a2a"
   },
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(data)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "eUS9B3iwCKLw",
    "outputId": "db9fa684-822e-4169-942f-c6f5ab578396"
   },
   "outputs": [],
   "source": [
    "df1['Resumen Procesado'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQ49f8pH0SoU"
   },
   "outputs": [],
   "source": [
    "Longitud=[]\n",
    "for i in df1['Noticia']:\n",
    "   Longitud.append(len(i.split()))\n",
    "\n",
    "df1['Longitud Noticia']=Longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_ABLG5jA4mN"
   },
   "outputs": [],
   "source": [
    "Longitud2=[]\n",
    "for i in df1['Resumen Procesado']:\n",
    "   Longitud2.append(len(i.split()))\n",
    "\n",
    "df1['Longitud Resumen']=Longitud2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "C-rLU2j71Sbo",
    "outputId": "ab3910b6-5f55-4ffd-8295-277603003c09"
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "a5DcLSkA1Y4U",
    "outputId": "20db8a35-a299-4238-aeb5-26ed6153fccd"
   },
   "outputs": [],
   "source": [
    "df1.hist(column='Longitud Noticia', bins= [100,200,300,400,500,600,700,800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "erSAi8bqBiU1",
    "outputId": "9ab242ee-2037-465b-8ea6-d1363d3dc692"
   },
   "outputs": [],
   "source": [
    "df1.hist(column='Longitud Resumen', bins= [2,4,6,8,10,12,14,16,18,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKutOwPE10BD"
   },
   "source": [
    "Observe que las longitudes con mayores incidencias son aquellas con menos de 200 palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jk2HH3oDnviZ",
    "outputId": "2f79251a-50bf-46e0-e00e-b7f45ec221d8"
   },
   "outputs": [],
   "source": [
    "\n",
    "cnt=0\n",
    "for i in df1['Noticia']:\n",
    "    if(len(i.split())<=200):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(df1['Noticia']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvEmTm3OpEkE"
   },
   "outputs": [],
   "source": [
    "Noticiasacotadas=[]\n",
    "Resumenes=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iprgsszanbh6"
   },
   "source": [
    "Veo que toman datos con una longitud maxima, no se si sea lo mejor para el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9NgrYfyoeeA"
   },
   "outputs": [],
   "source": [
    "for i in range(len(df1['Noticia'])):\n",
    "  if((df1['Longitud Noticia'][i])<=200 and df1['Longitud Resumen'][i]<=15 and df1['Longitud Resumen'][i]>=7):\n",
    "    Noticiasacotadas.append(df1['Noticia'][i])\n",
    "    Resumenes.append(df1['Resumen Procesado'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EouKTvTkpoEv",
    "outputId": "fb02ce68-ace2-4b20-a34f-ec46bad600ef"
   },
   "outputs": [],
   "source": [
    "print(len(Resumenes))\n",
    "print(len(Noticiasacotadas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cstK1SNDqhGC",
    "outputId": "87a01c96-5758-4ac5-e974-3cf0430e377e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-dc174aab-c66f-4862-838a-38f4593298d2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Noticias</th>\n",
       "      <th>Resumenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fallan reproductores zune microsoft en año nue...</td>\n",
       "      <td>los reproductores música zune dejan funcionar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>circuito interiorunos tristes contentos los qu...</td>\n",
       "      <td>unos tristes contentos los que andan plano cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la capillamuy movido naucalpan inicio año meno...</td>\n",
       "      <td>muy movido naucalpan inicio año menos departam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plaza públicapor vacaciones columna granados c...</td>\n",
       "      <td>por vacaciones columna granados chapa volverá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>el lector escribe la felicidad gran mayoría cu...</td>\n",
       "      <td>a gran mayoría cumplen buenos deseos fechas ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc174aab-c66f-4862-838a-38f4593298d2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-dc174aab-c66f-4862-838a-38f4593298d2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-dc174aab-c66f-4862-838a-38f4593298d2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            Noticias  \\\n",
       "0  fallan reproductores zune microsoft en año nue...   \n",
       "1  circuito interiorunos tristes contentos los qu...   \n",
       "2  la capillamuy movido naucalpan inicio año meno...   \n",
       "3  plaza públicapor vacaciones columna granados c...   \n",
       "4  el lector escribe la felicidad gran mayoría cu...   \n",
       "\n",
       "                                           Resumenes  \n",
       "0  los reproductores música zune dejan funcionar ...  \n",
       "1  unos tristes contentos los que andan plano cap...  \n",
       "2  muy movido naucalpan inicio año menos departam...  \n",
       "3  por vacaciones columna granados chapa volverá ...  \n",
       "4  a gran mayoría cumplen buenos deseos fechas ac...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfinal=pd.DataFrame({'Noticias': Noticiasacotadas, 'Resumenes': Resumenes})\n",
    "dfinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3qyXVBzqfLV"
   },
   "outputs": [],
   "source": [
    "#Generamos datos de pureba y entrenamiento\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(dfinal['Noticias'],dfinal['Resumenes'],test_size=0.3,random_state=42,shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UynRuXv7sr07"
   },
   "source": [
    "#Creamos un vocabulario/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctOXt59Wsqdw"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mk7HFoUs7KT"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70xXdg_6tlc_"
   },
   "outputs": [],
   "source": [
    "def readLangs(text, summary, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    text=np.array(text)\n",
    "    summary=np.array(summary)\n",
    "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(summary)\n",
    "        output_lang = Lang(text)\n",
    "    else:\n",
    "        input_lang = Lang(text)\n",
    "        output_lang = Lang(summary)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maY8Y3N0u5JP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOTraNTyu28u"
   },
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name,\"--------------------\", input_lang.n_words)\n",
    "    #print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYqqIvBZxuub",
    "outputId": "daca47ab-b662-4c3f-e62e-185294371590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 27875 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "['pide tricolor olvidar copa oroel mediocampista selección nacional gerardo torrado señaló pesar ideal ganarle estados unidos amplio marcador sucedido copa oro pasó historia quedó estadística cada partido situación encuentra tricolor eliminatoria mundialista prioritario ganar allá pensar goleada como situación importante ganar lo ideal ganar jugar bonito agradando afición hoy día importante ganar luego demás si da pues bienvenido pero si ganar tirándote cabeza haciendo gol último minuto importante ganar va sumar puntos cada partido diferente olvidarnos copa oro pasó quedó ahí estadísticas partido nuevo jugadores diferentes copa oro olvidarlo declaró torrado el jugador mexicano dijo ganar partido goles complicado actualidad tratándose juego eliminatoria pronostica partido cerrado torrado destacó después copa oro quedó estilo definido juego solamente aplican variantes conforme quiere cuerpo técnico acuerdo cada rival es equipo sólido forma juego todos jugadores importantes cualquiera puede jugar selección mexicana comenzó noche concentración juego estados unidos próxima semana reportaron jugadores último llegar delantero guillermo franco'\n",
      " 'falla convocatoria red seguridadla baja afluencia vecinos marcó arranque red seguridad satélite iniciativa pretende echar andar gobierno local ayuda asociación asistentes junta lunes aseguraron falló invitación parte autoridades municipales organismo vecinal a cita llegaron alrededor personas residentes circuito navegantes vocales asociación abandonaron sala terminar sesión atender junta mesa encuentro contemplado nombrar coordinador secretario red sólo nombró secretario manera interina dentro días definan dos representantes satélite fraccionamiento tan grande creo sólo puedan venir navegantes si vengo interesa dijo presentes mauricio rojas secretario interino alvarado subdirector vinculación ciudadana policía naucalpense impulsor proyecto aseveró invitación reuniones deberá llegar colonos vamos hacer proceso invitación dentro días fuerte mientras quedará coordinador manera interina respecto galo blanco delegado municipal satélite afirmó debe aprovechar infraestructura asociación colonos concretar avances materia seguridad que vocales asociación encarguen convocar vecinos representantes demás circuitos aquí podemos tener satélite representado próxima reunión red seguridad fijó lunes febrero horas'\n",
      " 'planea pepsico invertir mil mdd rusiapepsico inc prometió lunes invertirá mil millones dólares rusia próximos años aseguró confía mercado ruso pese país sufre peor recesión mercado rusia junto china india clave pepsico busca fortalecer ganancias debido recesión cambios hábito consumidor limitan incremento ventas estados unidos esta inversión refleja claramente gran confianza rusia compromiso largo plazo importante mercado dijo presidenta ejecutiva pepsico indra nooyi pesar crisis global afecta consumidor ruso mercado aún crece potencial crecer años futuro según jugadores industria hoy optimistas futuro rusia ansiamos continuar construyendo negocio aquí dijo siglo después líder soviético nikita khruschev probara icónica marca americana exhibición nacional americana moscú pepsico mayor embotelladora pepsi bottling group inc abren octava fábrica rusa cuya construcción costó millones apertura planta programada julio coincidirá reunión presidente barack obama par ruso dmitry cumbre busca restaurar confianza dos mayores potencias nucleares dañada gobiernos capacidad anual alcanza mil millones litros año planta convertirá mayor pepsico signo importancia mercado ruso compañía segundo mayor fabricante bebidas tras co invertido mil millones dólares mercado ruso última década incluyendo adquisición mil millones dólares mayor productor jugos país lebedyansky'\n",
      " ...\n",
      " 'busca francia cortar internet piratasla cámara baja francia aprobó proyecto pionero permite autoridades cortar acceso internet usuarios descarguen contenidos compañías espectáculos esperan medida arma piratería mientras críticos alegan viola derechos civiles entre surgen cuestionamientos cómo aplicará proyecto despertado interés exterior sectores música cine luchan proteger ingresos activistas defensores privacidad preocupa intervención ministerio cultura calcula mil usuarios franceses podrían ser desconectados sancionarse ciberpiratas ignoren advertencias enviadas correo electrónico carta oficial podrían perder conexión internet año además enfrentar multas mil euros mil dólares penas padres podrían ser penalizados supervisar actividades hijos si éstos descargan contenidos manera ilegal el servicio internet familia podría interrumpirse mes enfrentarían multas mil dólares si ignoran advertencias versión original propuesta restrictiva rechazada principios año inconstitucional el senado aprobó proyecto julio luego negociaciones cámara baja dio luz verde versión votos favor propuesta debe superar obstáculo convertirse ley ser aprobado pequeño comité ambas cámaras congreso encargado armonizar dos versiones presidente nicolás sarkozy casado modelo cantante carla bruni amigo poderosos propietarios medios apoya proyecto ministro cultura frederic mitterrand alabó labor legisladores los artistas recordarán menos valentía romper enfoque protegimos derechos gente quiere convertir red utopía libertaria dijo'\n",
      " 'costará mmdp plan shcpel acuerdo nacional favor familias empleo presentado hoy costo fiscal mil millones pesos obligará gobierno implementar mayor eficiencia gasto señaló secretaría monto total impulso demanda agregada traerá paquete medidas mil millones pesos representa casi ciento dependencia explicó parte recursos usará asumir compromisos contenidos dicho acuerdo provendrán mayoría excedentes ingresos ascienden casi mil millones anterior dijo objetivo evitar mayor déficit presupuestario así recortes señaló congelamiento precio gasolina reducción precios gas lp tarifas eléctricas industriales entraron vigor mismo miércoles costarán mil millones dependencia detalló acceder beneficios programa preservación empleo empresas atravesar trámite deberá pasar conciliación arbitraje así secretarías economía monto través programa otorgará empresas declaren paro técnico dependerá tiempo éstas permanezcan situación señaló'\n",
      " 'llegan actores acuerdo estudiosel sindicato actores cine televisión estados unidos alcanzó acuerdo tentativo alianza estudios cinematográficos pone fin nueve meses dura medición fuerzas partes informó viernes comunicado patronal la alianza productores cine televisión amptp sindicato actores américa sag anuncia partes alcanzaron acuerdo tentativo nuevos convenios productores sindicato actores establecidos pacto básico indicó comunicado amptp los detalles acuerdo alcanzado programas televisión producciones cinematográficas revelarán obtengan luz verde comité directivo sag reunirá próximo domingo tras previa reunión líderes sindicales los ángeles nueva york el sag mayor sindicato comediantes estados unidos integrado mil miembros presentará acuerdo tentativo junta directiva aprobación pasará afiliados ratificado agregó comunicado alianza agrupa principales estudios hollywood el contrato tres años establece condiciones trabajo losactores estados unidos venció junio desde entonces comediantes continuado trabajando pese ausencia nuevo acuerdo bajo reglas convenio anterior el sag reclamaba alza salarios actores reciben menos mil dólares anuales incremento dividendos venta dvds comercialización proyecciones películas series televisión internet así nuevas plataformas tecnológicas pero estudios rechazaron demandas acusar sag falta realismo sostuvieron nuevos medios tecnológicos aún generan rentabilidad la diferencia ambas partes hirió seno sindicato actores corriente apoyaba medidas fuerza huelga inclinaba mediación dejar trabajar dados difíciles tiempos económicos atraviesa estados unidos'] -------------------- 120463\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(x_train, y_train , False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quSICPK9x4NQ"
   },
   "outputs": [],
   "source": [
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vczfEl5JyJTe"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e77mIpavyHSx"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-U5bwNTUysqi"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0I0ptw9yxKn",
    "outputId": "62602539-5fa9-4a48-85f4-37f5dac55812"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27x64DD1zZMm"
   },
   "source": [
    "Encoder: Lo veremos apenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDPixFrizSPk"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.LSTM = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.LSTM(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size, device=device),torch.zeros(1, 1, self.hidden_size, device=device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snJ7XwNszgjo"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.LSTM = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.LSTM(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ch1w54hzkow"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Rz66FlgzqZw"
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size*2 , self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2 , self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.LSTM = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "        #print('Decoder --- atndecoder')\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        #print(\"inside forward decoder\")\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        #print(\"embedded size\", embedded.size())\n",
    "        #print(embedded[0].size()) #1,300\n",
    "        #print(hidden[0].size()) # 1, 1, 300\n",
    "        #print(\"diff or not\")\n",
    "\n",
    "        #temp = torch.cat((embedded[0], hidden[0]), 1)\n",
    "        \n",
    "        #print(temp)\n",
    "        #print(temp.size())\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0][0]), 1)), dim=1)\n",
    "        #print(\"after getting attn weights softmax\")\n",
    "        #print(attn_weights.size())\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.LSTM(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXztApzAzsR0"
   },
   "outputs": [],
   "source": [
    "#teacher_forcing_ratio = 0.5\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    #print('bbbbbbb-->>> input length', input_length)\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        #print(\"priting before error\")\n",
    "        #print(encoder_output.size())\n",
    "        #print(encoder_outputs.size())\n",
    "        temp = encoder_output[0, 0]\n",
    "        #print(temp)\n",
    "        encoder_outputs[ei] = temp\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    #use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    #Without teacher forcing: use its own predictions as the next input\n",
    "\n",
    "    #print('aaaaa-->>>')\n",
    "\n",
    "    for di in range(target_length):\n",
    "      decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "      decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "\n",
    "      topv, topi = decoder_output.topk(1)\n",
    "      \n",
    "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "      \n",
    "      loss += criterion(decoder_output, target_tensor[di])\n",
    "      \n",
    "      if decoder_input.item() == EOS_token:\n",
    "             break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhThtQEQz_1q"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3i3FgEv0BgZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-gbrXtd0D14"
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    print(\"Training....\")\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        if iter% 1000 == 0:\n",
    "            print(iter,\"/\",n_iters + 1)\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        input_length = input_tensor.size(0)\n",
    "        if(input_length > 150):\n",
    "          #print(input_length)\n",
    "          continue\n",
    "      \n",
    "        loss = train(input_tensor, target_tensor, encoder,decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LahQIb30OtF"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        #print('cccccc->>>>')\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoXkVwh10TfR"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=5):\n",
    "    text=list()\n",
    "    headline=list()\n",
    "    pred_headline=list()    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        \n",
    "        if(len(pair[0].split())>=150):\n",
    "          continue\n",
    "        else:\n",
    "          if(i%1000==0):\n",
    "            print(i*100/n,\"% complete\")\n",
    "          \n",
    "          #print('>', pair[0])\n",
    "          text.append(pair[0])\n",
    "          #print('=', pair[1])\n",
    "          headline.append(pair[1])\n",
    "          output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "          output_sentence = ' '.join(output_words)\n",
    "          pred_headline.append(output_sentence)\n",
    "          #print('<', output_sentence)\n",
    "          #print('')\n",
    "    return(text,headline,pred_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ban2o9oaHcls",
    "outputId": "8061ed64-8ebe-41cd-e194-5d1732d02339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "1000 / 150001\n",
      "1m 13s (- 181m 23s) (1000 0%) 2.6603\n",
      "2000 / 150001\n",
      "3000 / 150001\n",
      "2m 56s (- 143m 49s) (3000 2%) 3.6433\n",
      "4000 / 150001\n",
      "5000 / 150001\n",
      "4m 44s (- 137m 21s) (5000 3%) 5.4562\n",
      "6000 / 150001\n",
      "5m 40s (- 136m 14s) (6000 4%) 3.4113\n",
      "7000 / 150001\n",
      "8000 / 150001\n",
      "9000 / 150001\n",
      "8m 31s (- 133m 38s) (9000 6%) 10.9023\n",
      "10000 / 150001\n",
      "11000 / 150001\n",
      "10m 27s (- 132m 3s) (11000 7%) 7.3648\n",
      "12000 / 150001\n",
      "11m 23s (- 130m 59s) (12000 8%) 3.7446\n",
      "13000 / 150001\n",
      "14000 / 150001\n",
      "13m 19s (- 129m 22s) (14000 9%) 7.3821\n",
      "15000 / 150001\n",
      "14m 15s (- 128m 21s) (15000 10%) 3.6581\n",
      "16000 / 150001\n",
      "15m 11s (- 127m 16s) (16000 10%) 3.6070\n",
      "17000 / 150001\n",
      "18000 / 150001\n",
      "17m 4s (- 125m 9s) (18000 12%) 7.4968\n",
      "19000 / 150001\n",
      "18m 0s (- 124m 12s) (19000 12%) 3.8954\n",
      "20000 / 150001\n",
      "18m 59s (- 123m 26s) (20000 13%) 3.7415\n",
      "21000 / 150001\n",
      "19m 58s (- 122m 39s) (21000 14%) 3.6938\n",
      "22000 / 150001\n",
      "23000 / 150001\n",
      "24000 / 150001\n",
      "22m 47s (- 119m 38s) (24000 16%) 10.9567\n",
      "25000 / 150001\n",
      "26000 / 150001\n",
      "24m 43s (- 117m 53s) (26000 17%) 7.5750\n",
      "27000 / 150001\n",
      "28000 / 150001\n",
      "29000 / 150001\n",
      "30000 / 150001\n",
      "28m 35s (- 114m 21s) (30000 20%) 15.4446\n",
      "31000 / 150001\n",
      "29m 33s (- 113m 26s) (31000 20%) 3.7851\n",
      "32000 / 150001\n",
      "30m 33s (- 112m 41s) (32000 21%) 4.0832\n",
      "33000 / 150001\n",
      "34000 / 150001\n",
      "32m 32s (- 111m 1s) (34000 22%) 7.7449\n",
      "35000 / 150001\n",
      "33m 30s (- 110m 4s) (35000 23%) 3.7590\n",
      "36000 / 150001\n",
      "37000 / 150001\n",
      "35m 27s (- 108m 18s) (37000 24%) 7.8124\n",
      "38000 / 150001\n",
      "36m 23s (- 107m 16s) (38000 25%) 3.6557\n",
      "39000 / 150001\n",
      "37m 20s (- 106m 16s) (39000 26%) 3.5952\n",
      "40000 / 150001\n",
      "38m 15s (- 105m 13s) (40000 26%) 3.5207\n",
      "41000 / 150001\n",
      "39m 13s (- 104m 17s) (41000 27%) 3.8458\n",
      "42000 / 150001\n",
      "43000 / 150001\n",
      "41m 7s (- 102m 21s) (43000 28%) 7.5031\n",
      "44000 / 150001\n",
      "42m 6s (- 101m 25s) (44000 29%) 3.7615\n",
      "45000 / 150001\n",
      "43m 3s (- 100m 27s) (45000 30%) 3.6762\n",
      "46000 / 150001\n",
      "44m 1s (- 99m 31s) (46000 30%) 3.7201\n",
      "47000 / 150001\n",
      "48000 / 150001\n",
      "45m 54s (- 97m 33s) (48000 32%) 7.2964\n",
      "49000 / 150001\n",
      "50000 / 150001\n",
      "47m 48s (- 95m 36s) (50000 33%) 7.6022\n",
      "51000 / 150001\n",
      "48m 47s (- 94m 43s) (51000 34%) 3.9571\n",
      "52000 / 150001\n",
      "49m 47s (- 93m 49s) (52000 34%) 3.8877\n",
      "53000 / 150001\n",
      "50m 44s (- 92m 52s) (53000 35%) 3.7534\n",
      "54000 / 150001\n",
      "51m 43s (- 91m 57s) (54000 36%) 3.7975\n",
      "55000 / 150001\n",
      "56000 / 150001\n",
      "53m 39s (- 90m 4s) (56000 37%) 7.4221\n",
      "57000 / 150001\n",
      "58000 / 150001\n",
      "55m 37s (- 88m 13s) (58000 38%) 7.7090\n",
      "59000 / 150001\n",
      "60000 / 150001\n",
      "57m 34s (- 86m 21s) (60000 40%) 7.7423\n",
      "61000 / 150001\n",
      "62000 / 150001\n",
      "59m 33s (- 84m 31s) (62000 41%) 7.8087\n",
      "63000 / 150001\n",
      "60m 32s (- 83m 36s) (63000 42%) 3.8262\n",
      "64000 / 150001\n",
      "61m 31s (- 82m 39s) (64000 42%) 3.8798\n",
      "65000 / 150001\n",
      "62m 28s (- 81m 42s) (65000 43%) 3.8681\n",
      "66000 / 150001\n",
      "63m 28s (- 80m 46s) (66000 44%) 3.7978\n",
      "67000 / 150001\n",
      "64m 25s (- 79m 48s) (67000 44%) 3.6976\n",
      "68000 / 150001\n",
      "65m 23s (- 78m 50s) (68000 45%) 3.7606\n",
      "69000 / 150001\n",
      "66m 20s (- 77m 53s) (69000 46%) 3.6527\n",
      "70000 / 150001\n",
      "67m 16s (- 76m 53s) (70000 46%) 3.6340\n",
      "71000 / 150001\n",
      "68m 16s (- 75m 57s) (71000 47%) 3.8154\n",
      "72000 / 150001\n",
      "69m 13s (- 74m 59s) (72000 48%) 3.6761\n",
      "73000 / 150001\n",
      "74000 / 150001\n",
      "71m 8s (- 73m 3s) (74000 49%) 7.3465\n",
      "75000 / 150001\n",
      "72m 6s (- 72m 6s) (75000 50%) 3.7162\n",
      "76000 / 150001\n",
      "73m 6s (- 71m 10s) (76000 50%) 3.7618\n",
      "77000 / 150001\n",
      "78000 / 150001\n",
      "79000 / 150001\n",
      "80000 / 150001\n",
      "81000 / 150001\n",
      "77m 50s (- 66m 18s) (81000 54%) 18.1862\n",
      "82000 / 150001\n",
      "78m 48s (- 65m 20s) (82000 54%) 3.6309\n",
      "83000 / 150001\n",
      "79m 46s (- 64m 23s) (83000 55%) 3.8703\n",
      "84000 / 150001\n",
      "80m 45s (- 63m 27s) (84000 56%) 3.7921\n",
      "85000 / 150001\n",
      "86000 / 150001\n",
      "87000 / 150001\n",
      "83m 38s (- 60m 33s) (87000 57%) 10.9956\n",
      "88000 / 150001\n",
      "89000 / 150001\n",
      "85m 31s (- 58m 36s) (89000 59%) 7.1245\n",
      "90000 / 150001\n",
      "91000 / 150001\n",
      "92000 / 150001\n",
      "93000 / 150001\n",
      "89m 23s (- 54m 47s) (93000 62%) 14.9903\n",
      "94000 / 150001\n",
      "90m 19s (- 53m 48s) (94000 62%) 3.6357\n",
      "95000 / 150001\n",
      "91m 19s (- 52m 52s) (95000 63%) 3.8728\n",
      "96000 / 150001\n",
      "92m 17s (- 51m 55s) (96000 64%) 3.5726\n",
      "97000 / 150001\n",
      "93m 16s (- 50m 58s) (97000 64%) 3.9176\n",
      "98000 / 150001\n",
      "99000 / 150001\n",
      "100000 / 150001\n",
      "101000 / 150001\n",
      "97m 8s (- 47m 7s) (101000 67%) 15.0727\n",
      "102000 / 150001\n",
      "98m 5s (- 46m 9s) (102000 68%) 3.7452\n",
      "103000 / 150001\n",
      "104000 / 150001\n",
      "105000 / 150001\n",
      "101m 0s (- 43m 17s) (105000 70%) 11.4145\n",
      "106000 / 150001\n",
      "101m 58s (- 42m 19s) (106000 70%) 3.8693\n",
      "107000 / 150001\n",
      "102m 57s (- 41m 22s) (107000 71%) 3.8232\n",
      "108000 / 150001\n",
      "103m 55s (- 40m 25s) (108000 72%) 3.8260\n",
      "109000 / 150001\n",
      "104m 54s (- 39m 27s) (109000 72%) 3.8285\n",
      "110000 / 150001\n",
      "105m 53s (- 38m 30s) (110000 73%) 3.8901\n",
      "111000 / 150001\n",
      "106m 52s (- 37m 32s) (111000 74%) 3.7198\n",
      "112000 / 150001\n",
      "107m 53s (- 36m 36s) (112000 74%) 4.0113\n",
      "113000 / 150001\n",
      "114000 / 150001\n",
      "109m 46s (- 34m 40s) (114000 76%) 7.4308\n",
      "115000 / 150001\n",
      "110m 46s (- 33m 42s) (115000 76%) 3.8186\n",
      "116000 / 150001\n",
      "111m 44s (- 32m 45s) (116000 77%) 3.7685\n",
      "117000 / 150001\n",
      "112m 43s (- 31m 47s) (117000 78%) 3.7366\n",
      "118000 / 150001\n",
      "113m 42s (- 30m 50s) (118000 78%) 3.8480\n",
      "119000 / 150001\n",
      "114m 41s (- 29m 52s) (119000 79%) 3.8371\n",
      "120000 / 150001\n",
      "121000 / 150001\n",
      "122000 / 150001\n",
      "117m 38s (- 26m 59s) (122000 81%) 11.6519\n",
      "123000 / 150001\n",
      "118m 37s (- 26m 2s) (123000 82%) 3.8344\n",
      "124000 / 150001\n",
      "119m 35s (- 25m 4s) (124000 82%) 3.8017\n",
      "125000 / 150001\n",
      "120m 36s (- 24m 7s) (125000 83%) 4.0032\n",
      "126000 / 150001\n",
      "121m 35s (- 23m 9s) (126000 84%) 4.0532\n",
      "127000 / 150001\n",
      "122m 33s (- 22m 11s) (127000 84%) 3.8265\n",
      "128000 / 150001\n",
      "123m 31s (- 21m 13s) (128000 85%) 3.8791\n",
      "129000 / 150001\n",
      "124m 28s (- 20m 15s) (129000 86%) 3.8349\n",
      "130000 / 150001\n",
      "125m 29s (- 19m 18s) (130000 86%) 3.9889\n",
      "131000 / 150001\n",
      "132000 / 150001\n",
      "127m 28s (- 17m 22s) (132000 88%) 7.8674\n",
      "133000 / 150001\n",
      "128m 25s (- 16m 24s) (133000 88%) 3.8270\n",
      "134000 / 150001\n",
      "129m 25s (- 15m 27s) (134000 89%) 3.8835\n",
      "135000 / 150001\n",
      "130m 24s (- 14m 29s) (135000 90%) 3.8850\n",
      "136000 / 150001\n",
      "131m 21s (- 13m 31s) (136000 90%) 3.7555\n",
      "137000 / 150001\n",
      "138000 / 150001\n",
      "139000 / 150001\n",
      "140000 / 150001\n",
      "135m 17s (- 9m 39s) (140000 93%) 15.3787\n"
     ]
    }
   ],
   "source": [
    "#Entrenamineto:\n",
    "hidden_size = 200\n",
    "encoder2 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder2 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder2, attn_decoder2, 150000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TOgftOG_oEP"
   },
   "outputs": [],
   "source": [
    "torch.save(encoder2.state_dict(), '/content/drive/MyDrive/encoderbasecorregidp.w')\n",
    "torch.save(attn_decoder2.state_dict(), '/content/drive/MyDrive/atentionbasecorregido.w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTBYKylDGs4C",
    "outputId": "9f017b22-7a39-4e6e-8d6a-ec0ef58c286e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % complete\n",
      "6.666666666666667 % complete\n",
      "40.0 % complete\n",
      "46.666666666666664 % complete\n",
      "60.0 % complete\n",
      "66.66666666666667 % complete\n",
      "80.0 % complete\n",
      "86.66666666666667 % complete\n",
      "93.33333333333333 % complete\n"
     ]
    }
   ],
   "source": [
    "text,headline,pred_headline=evaluateRandomly(encoder1, attn_decoder1,15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UziGNThJsc-",
    "outputId": "e0120e89-7064-4075-d479-26cf6267c4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666666666666667 % complete\n",
      "13.333333333333334 % complete\n",
      "20.0 % complete\n",
      "33.333333333333336 % complete\n",
      "40.0 % complete\n",
      "46.666666666666664 % complete\n",
      "53.333333333333336 % complete\n",
      "73.33333333333333 % complete\n",
      "86.66666666666667 % complete\n",
      "93.33333333333333 % complete\n"
     ]
    }
   ],
   "source": [
    "text,headline,pred_headline=evaluateRandomly(encoder2, attn_decoder2,15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJYWqAbuI1_t"
   },
   "outputs": [],
   "source": [
    "pred_df_LSTM=pd.DataFrame()\n",
    "pred_df_LSTM['Noticias']=text\n",
    "pred_df_LSTM['Resumenes']=headline\n",
    "pred_df_LSTM['ResumenNew']=pred_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SbswHIEIg_A",
    "outputId": "28e03d3d-ca76-453f-9011-2b56d6eb6cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "pred_df_LSTM.to_csv('/content/drive/My Drive/BaseLSTM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "YRiQeFgar1mp",
    "outputId": "292db996-7bcc-4bbe-f219-88689f01f7a3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'el <EOS>'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_LSTM['ResumenNew'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwrLpqkcBjcU",
    "outputId": "ab62a415-90a4-4936-f1d4-f10a8d27eab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['gana ica contrato pemexla petrolera estatal mexicana pemex dijo martes asignó contrato unidad ica construir planta criogénica monto cercano millones comunicado pemex dijo resultó ganadora propuesta presentada ica fluor daniel linde process construcción planta poza rica veracruz costa golfo méxico la ejecución obra forma parte programa infraestructura permitirá hacer frente oferta creciente gas húmedo dulce proveniente proyecto chicontepec dijo petrolera detalló contrato consta dos partes monto millones pesos millones dólares millones plazo ejecución días partir agosto espera año proyectos inversión pemex motor crecimiento país ayuden alcanzar meta crecimiento ventas ciento'],\n",
       " ['petróleos mexicanos asignó contrato ica construcción planta criogénica monto cercano millones dólares'],\n",
       " ['el bolsa mexicana méxico dijo dijo ciento mil <EOS>'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluateRandomly(encoder2, attn_decoder2,1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
